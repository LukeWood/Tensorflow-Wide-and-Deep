{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Car Evaluation ðŸš— 2.5 (McQueen Edition)\n",
    "   \n",
    "## Lab Seven: Wide and Deep Network Architectures\n",
    "   \n",
    "### Justin Ledford, Luke Wood, Traian Pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import plotly\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dataset Selection\n",
    "\n",
    "Select a dataset identically to lab one. That is, the dataset must be table data. In terms of generalization performance, it is helpful to have a large dataset for building a wide and deep network. It is also helpful to have many different categorical features to create the embeddings and cross-product embeddings. It is fine to perform binary classification or multi-class classification.\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/\n",
    "\n",
    "___ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preparation (40 points total)\n",
    "   \n",
    "### [10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). \n",
    "   \n",
    "### [10 points] Identify groups of features in your data that should be combined into cross-product features.\n",
    "   \n",
    "### [10 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "   \n",
    "### [10 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "\n",
    "# Get column names\n",
    "r = requests.get('https://raw.githubusercontent.com/LukeWoodSMU/WillBeRenamed/master/col_names.txt')\n",
    "\n",
    "if r.status_code == 200:\n",
    "    columns = r.text.split('\\n')[:-1]\n",
    "else:\n",
    "    print('Error loading column names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'class of worker', 'industry code', 'occupation code', 'education', 'wage per hour', 'enrolled in edu inst last wk', 'marital status', 'major industry code', 'major occupation code', 'race', 'hispanic origin', 'sex', 'member of a labor union', 'reason for unemployment', 'full or part time employment stat', 'capital gains', 'capital losses', 'dividends from stocks', 'tax filer status', 'region of previous residence', 'state of previous residence', 'detailed household and family stat', 'detailed household summary in household', 'migration code-change in msa', 'migration code-change in reg', 'migration code-move within reg', 'live in this house 1 year ago', 'migration prev res in sunbelt', 'num persons worked for employer', 'family members under 18', 'country of birth father', 'country of birth mother', 'country of birth self', 'citizenship', 'own business or self employed', \"fill inc questionnaire for veteran's admin\", 'veterans benefits', 'weeks worked in year', 'year', 'income']\n"
     ]
    }
   ],
   "source": [
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>class of worker</th>\n",
       "      <th>industry code</th>\n",
       "      <th>occupation code</th>\n",
       "      <th>education</th>\n",
       "      <th>wage per hour</th>\n",
       "      <th>enrolled in edu inst last wk</th>\n",
       "      <th>marital status</th>\n",
       "      <th>major industry code</th>\n",
       "      <th>major occupation code</th>\n",
       "      <th>...</th>\n",
       "      <th>country of birth father</th>\n",
       "      <th>country of birth mother</th>\n",
       "      <th>country of birth self</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>own business or self employed</th>\n",
       "      <th>fill inc questionnaire for veteran's admin</th>\n",
       "      <th>veterans benefits</th>\n",
       "      <th>weeks worked in year</th>\n",
       "      <th>year</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Self-employed-not incorporated</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Precision production craft &amp; repair</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelors degree(BA AB BS)</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Finance insurance and real estate</td>\n",
       "      <td>Executive admin and managerial</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Machine operators assmblrs &amp; inspctrs</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                  class of worker  industry code  occupation code  \\\n",
       "1   58   Self-employed-not incorporated              4               34   \n",
       "3    9                  Not in universe              0                0   \n",
       "4   10                  Not in universe              0                0   \n",
       "6   42                          Private             34                3   \n",
       "9   34                          Private              4               37   \n",
       "\n",
       "                     education  wage per hour enrolled in edu inst last wk  \\\n",
       "1   Some college but no degree              0              Not in universe   \n",
       "3                     Children              0              Not in universe   \n",
       "4                     Children              0              Not in universe   \n",
       "6   Bachelors degree(BA AB BS)              0              Not in universe   \n",
       "9   Some college but no degree              0              Not in universe   \n",
       "\n",
       "                     marital status                 major industry code  \\\n",
       "1                          Divorced                        Construction   \n",
       "3                     Never married         Not in universe or children   \n",
       "4                     Never married         Not in universe or children   \n",
       "6   Married-civilian spouse present   Finance insurance and real estate   \n",
       "9   Married-civilian spouse present                        Construction   \n",
       "\n",
       "                    major occupation code    ...     country of birth father  \\\n",
       "1     Precision production craft & repair    ...               United-States   \n",
       "3                         Not in universe    ...               United-States   \n",
       "4                         Not in universe    ...               United-States   \n",
       "6          Executive admin and managerial    ...               United-States   \n",
       "9   Machine operators assmblrs & inspctrs    ...               United-States   \n",
       "\n",
       "  country of birth mother country of birth self  \\\n",
       "1           United-States         United-States   \n",
       "3           United-States         United-States   \n",
       "4           United-States         United-States   \n",
       "6           United-States         United-States   \n",
       "9           United-States         United-States   \n",
       "\n",
       "                          citizenship own business or self employed  \\\n",
       "1   Native- Born in the United States                             0   \n",
       "3   Native- Born in the United States                             0   \n",
       "4   Native- Born in the United States                             0   \n",
       "6   Native- Born in the United States                             0   \n",
       "9   Native- Born in the United States                             0   \n",
       "\n",
       "  fill inc questionnaire for veteran's admin  veterans benefits  \\\n",
       "1                            Not in universe                  2   \n",
       "3                            Not in universe                  0   \n",
       "4                            Not in universe                  0   \n",
       "6                            Not in universe                  2   \n",
       "9                            Not in universe                  2   \n",
       "\n",
       "   weeks worked in year  year     income  \n",
       "1                    52    94   - 50000.  \n",
       "3                     0    94   - 50000.  \n",
       "4                     0    94   - 50000.  \n",
       "6                    52    94   - 50000.  \n",
       "9                    52    94   - 50000.  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "        'https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.data.gz',\n",
    "        compression='gzip', header=None, index_col=False)\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "        'https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.test.gz',\n",
    "        compression='gzip', header=None, index_col=False)\n",
    "\n",
    "\n",
    "# Remove weight columns\n",
    "df_train.drop(24, 1, inplace=True)\n",
    "df_test.drop(24, 1, inplace=True)\n",
    "\n",
    "df_train.columns = columns\n",
    "df_test.columns = columns\n",
    "\n",
    "# Remove rows with missing data and reset index\n",
    "df_train.replace(to_replace=' ?',value=np.nan, inplace=True)\n",
    "df_train.dropna(inplace=True)\n",
    "df_train.reset_index()\n",
    "\n",
    "df_test.replace(to_replace=' ?',value=np.nan, inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "df_test.reset_index()\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class of worker', 'industry code', 'occupation code', 'education', 'enrolled in edu inst last wk', 'marital status', 'major industry code', 'major occupation code', 'race', 'hispanic origin', 'sex', 'member of a labor union', 'reason for unemployment', 'full or part time employment stat', 'tax filer status', 'region of previous residence', 'state of previous residence', 'detailed household and family stat', 'detailed household summary in household', 'migration code-change in msa', 'migration code-change in reg', 'migration code-move within reg', 'live in this house 1 year ago', 'migration prev res in sunbelt', 'family members under 18', 'country of birth father', 'country of birth mother', 'country of birth self', 'citizenship', 'own business or self employed', \"fill inc questionnaire for veteran's admin\", 'veterans benefits', 'year']\n"
     ]
    }
   ],
   "source": [
    "# Process data:\n",
    "\n",
    "# check income values consistent (only 2 values)\n",
    "\n",
    "# replace categorical with one hot encoding\n",
    "# scale continuous\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "labels = dict() \n",
    "\n",
    "r = requests.get('https://raw.githubusercontent.com/LukeWoodSMU/WillBeRenamed/master/categorical.txt')\n",
    "categorical_labels = r.text.split('\\n')[:-1]\n",
    "print(categorical_labels)\n",
    "\n",
    "for col in categorical_labels + ['income']:\n",
    "    # strip extra space in strings\n",
    "    if df_train[col].dtype == 'object':\n",
    "        df_train[col] = df_train[col].str.strip()\n",
    "    if df_test[col].dtype == 'object':\n",
    "        df_test[col] = df_test[col].str.strip()\n",
    "        \n",
    "    # convert to ints for one hot encoder to work\n",
    "    \n",
    "    # keep labels for reference \n",
    "    labels[col] = list(set(df_train[col].unique()) | set(df_test[col].unique()))\n",
    "    \n",
    "    df_train[col].replace(to_replace=labels[col],\n",
    "                            value=np.arange(len(labels[col])),\n",
    "                            inplace=True)\n",
    "    df_test[col].replace(to_replace=labels[col],\n",
    "                            value=np.arange(len(labels[col])),\n",
    "                            inplace=True)\n",
    "    \n",
    "    \n",
    "r = requests.get('https://raw.githubusercontent.com/LukeWoodSMU/WillBeRenamed/master/continuous.txt')\n",
    "continuous_labels = r.text.split('\\n')[:-1]\n",
    "\n",
    "\n",
    "for col in continuous_labels:\n",
    "    df_train[col] = df_train[col].astype(np.float32)\n",
    "    df_test[col] = df_test[col].astype(np.float32)\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    df_train[col] = ss.fit_transform(df_train[col].values.reshape(-1, 1))\n",
    "    df_test[col] = ss.transform(df_test[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.learn.python import SKCompat\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "tf.logging.set_verbosity(tf.logging.WARN) # control the verbosity of tensor flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's start with the TF example (manipulated to work with new syntax)\n",
    "# https://www.tensorflow.org/tutorials/wide_and_deep\n",
    "def process_input(df, label_header, categ_headers, numeric_headers):\n",
    "    # input: what ever you need it to be\n",
    "    # output: (dict of feature columns as tensors), (labels as tensors)\n",
    "    \n",
    "    # ========Process Inputs=========\n",
    "    # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "    # the values of that column stored in a constant Tensor.\n",
    "    continuous_cols = {k: tf.expand_dims( # make it a column vector\n",
    "                            tf.cast( # cast to a float32\n",
    "                                tf.constant(df[k].values), \n",
    "                                tf.float32), \n",
    "                            1)\n",
    "                       for k in numeric_headers}\n",
    "    \n",
    "    # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "    # to the values of that column stored as constant Tensors (numeric)\n",
    "    # then use tensor flow to one hot encode them using the given number of classes \n",
    "    # name of encoder is **_int need to map only to **\n",
    "    categorical_cols = {k: tf.one_hot(indices=tf.constant(df[k].values),\n",
    "                                      depth=len(labels[k])) \n",
    "                        for k in categ_headers}\n",
    "    \n",
    "    # Merges the two dictionaries into one.\n",
    "    feature_cols = dict(continuous_cols)\n",
    "    feature_cols.update(categorical_cols)\n",
    "    \n",
    "    # Convert the label column into a constant Tensor.\n",
    "    label = None\n",
    "    if label_header is not None:\n",
    "        label = tf.constant(df[label_header].values)\n",
    "        \n",
    "    return feature_cols, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': <tf.Tensor 'ExpandDims_21:0' shape=(95130, 1) dtype=float32>,\n",
       "  'capital gains': <tf.Tensor 'ExpandDims_23:0' shape=(95130, 1) dtype=float32>,\n",
       "  'capital losses': <tf.Tensor 'ExpandDims_24:0' shape=(95130, 1) dtype=float32>,\n",
       "  'citizenship': <tf.Tensor 'one_hot_130:0' shape=(95130, 5) dtype=float32>,\n",
       "  'class of worker': <tf.Tensor 'one_hot_102:0' shape=(95130, 9) dtype=float32>,\n",
       "  'country of birth father': <tf.Tensor 'one_hot_127:0' shape=(95130, 40) dtype=float32>,\n",
       "  'country of birth mother': <tf.Tensor 'one_hot_128:0' shape=(95130, 40) dtype=float32>,\n",
       "  'country of birth self': <tf.Tensor 'one_hot_129:0' shape=(95130, 41) dtype=float32>,\n",
       "  'detailed household and family stat': <tf.Tensor 'one_hot_119:0' shape=(95130, 38) dtype=float32>,\n",
       "  'detailed household summary in household': <tf.Tensor 'one_hot_120:0' shape=(95130, 8) dtype=float32>,\n",
       "  'dividends from stocks': <tf.Tensor 'ExpandDims_25:0' shape=(95130, 1) dtype=float32>,\n",
       "  'education': <tf.Tensor 'one_hot_105:0' shape=(95130, 17) dtype=float32>,\n",
       "  'enrolled in edu inst last wk': <tf.Tensor 'one_hot_106:0' shape=(95130, 3) dtype=float32>,\n",
       "  'family members under 18': <tf.Tensor 'one_hot_126:0' shape=(95130, 5) dtype=float32>,\n",
       "  \"fill inc questionnaire for veteran's admin\": <tf.Tensor 'one_hot_132:0' shape=(95130, 3) dtype=float32>,\n",
       "  'full or part time employment stat': <tf.Tensor 'one_hot_115:0' shape=(95130, 1) dtype=float32>,\n",
       "  'hispanic origin': <tf.Tensor 'one_hot_111:0' shape=(95130, 10) dtype=float32>,\n",
       "  'industry code': <tf.Tensor 'one_hot_103:0' shape=(95130, 52) dtype=float32>,\n",
       "  'live in this house 1 year ago': <tf.Tensor 'one_hot_124:0' shape=(95130, 3) dtype=float32>,\n",
       "  'major industry code': <tf.Tensor 'one_hot_108:0' shape=(95130, 24) dtype=float32>,\n",
       "  'major occupation code': <tf.Tensor 'one_hot_109:0' shape=(95130, 15) dtype=float32>,\n",
       "  'marital status': <tf.Tensor 'one_hot_107:0' shape=(95130, 7) dtype=float32>,\n",
       "  'member of a labor union': <tf.Tensor 'one_hot_113:0' shape=(95130, 3) dtype=float32>,\n",
       "  'migration code-change in msa': <tf.Tensor 'one_hot_121:0' shape=(95130, 9) dtype=float32>,\n",
       "  'migration code-change in reg': <tf.Tensor 'one_hot_122:0' shape=(95130, 8) dtype=float32>,\n",
       "  'migration code-move within reg': <tf.Tensor 'one_hot_123:0' shape=(95130, 9) dtype=float32>,\n",
       "  'migration prev res in sunbelt': <tf.Tensor 'one_hot_125:0' shape=(95130, 3) dtype=float32>,\n",
       "  'num persons worked for employer': <tf.Tensor 'ExpandDims_26:0' shape=(95130, 1) dtype=float32>,\n",
       "  'occupation code': <tf.Tensor 'one_hot_104:0' shape=(95130, 47) dtype=float32>,\n",
       "  'own business or self employed': <tf.Tensor 'one_hot_131:0' shape=(95130, 3) dtype=float32>,\n",
       "  'race': <tf.Tensor 'one_hot_110:0' shape=(95130, 5) dtype=float32>,\n",
       "  'reason for unemployment': <tf.Tensor 'one_hot_114:0' shape=(95130, 6) dtype=float32>,\n",
       "  'region of previous residence': <tf.Tensor 'one_hot_117:0' shape=(95130, 6) dtype=float32>,\n",
       "  'sex': <tf.Tensor 'one_hot_112:0' shape=(95130, 2) dtype=float32>,\n",
       "  'state of previous residence': <tf.Tensor 'one_hot_118:0' shape=(95130, 50) dtype=float32>,\n",
       "  'tax filer status': <tf.Tensor 'one_hot_116:0' shape=(95130, 6) dtype=float32>,\n",
       "  'veterans benefits': <tf.Tensor 'one_hot_133:0' shape=(95130, 3) dtype=float32>,\n",
       "  'wage per hour': <tf.Tensor 'ExpandDims_22:0' shape=(95130, 1) dtype=float32>,\n",
       "  'weeks worked in year': <tf.Tensor 'ExpandDims_27:0' shape=(95130, 1) dtype=float32>,\n",
       "  'year': <tf.Tensor 'one_hot_134:0' shape=(95130, 1) dtype=float32>},\n",
       " <tf.Tensor 'Const_166:0' shape=(95130,) dtype=int64>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_input(df_train,'income',categorical_labels, continuous_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# update the model to take input features as a dictionary\n",
    "def MLP(dict_features, targets, mode):\n",
    "    # the prototype for this function is as follows\n",
    "    # input:  (features, targets) \n",
    "    # output: (predictions, loss, train_op)\n",
    "    \n",
    "    #=======DECODE FEATURES================\n",
    "    # now let's combine the tensors from the input dictionary\n",
    "    # into a list of the feature columns\n",
    "    features = [dict_features[x] for x in continuous_labels+categorical_labels]\n",
    "   \n",
    "    # also add in the one hot encoded features\n",
    "    for col in categorical_labels:\n",
    "        features.append(dict_features[col])\n",
    "    \n",
    "    # now we can just combine all the features together\n",
    "    features = tf.concat(values=features,axis=1)\n",
    "    \n",
    "    # =====SETUP ARCHITECTURE=====\n",
    "    # we can use functions from learn to add layers and complexity to the model\n",
    "    # pass features through one hidden layer with relu activation\n",
    "    features = layers.relu(features, num_outputs=50) \n",
    "    # now pass the features through a fully connected layer\n",
    "    features = layers.fully_connected(features, num_outputs=1) \n",
    "    # and pass them through a sigmoid activation\n",
    "    output_layer = tf.sigmoid(features) \n",
    "    # reshape the output to be one dimensional\n",
    "    predictions = tf.reshape(output_layer, [-1])\n",
    "    \n",
    "    # depending on the mode, we may not want to evaluate these\n",
    "    loss_mse = None\n",
    "    train_op = None\n",
    "    \n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    if mode != learn.ModeKeys.INFER:\n",
    "        # =====LOSS=======\n",
    "        # we want to use MSE as our loss function\n",
    "        loss_mse = tf.losses.mean_squared_error(targets, predictions) \n",
    "    \n",
    "    if mode == learn.ModeKeys.TRAIN:\n",
    "        # =====OPTIMIZER PARAMS========\n",
    "        # now let's setup how we want thing to optimize \n",
    "        train_op = layers.optimize_loss(\n",
    "            loss=loss_mse, \n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            optimizer='Adagrad', # adaptive gradient, so that the learning rate is not SO important \n",
    "            learning_rate=0.1)\n",
    "    \n",
    "    # what format to have the output in when calling clf.predict?\n",
    "    predictions_out = predictions>0.5\n",
    "    \n",
    "    return model_fn_lib.ModelFnOps(\n",
    "      mode=mode, predictions={'incomes':predictions_out}, loss=loss_mse, train_op=train_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_ixtxxwx\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = learn.Estimator(model_fn=MLP)\n",
    "\n",
    "# when we provide the process function, they expect us to control the mini-batch\n",
    "clf.fit(input_fn=\n",
    "        lambda:process_input(df_train,'income',categorical_labels, continuous_labels), \n",
    "        steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test = df_test['income'].values.astype(np.int)\n",
    "\n",
    "yhat = clf.predict(input_fn=\n",
    "                   lambda:process_input(df_test, None,categorical_labels, continuous_labels))\n",
    "# the output is now an iterable value, so we need to step over it\n",
    "yhat = [x['incomes'] for x in yhat]\n",
    "print(confusion_matrix(y_test,yhat),\n",
    "      accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Modeling (50 points total)\n",
    "   \n",
    "### [20 points] Create a combined wide and deep network to classify your data using tensorflow.\n",
    "   \n",
    "### [20 points] Investigate generalization performance by altering the number of layers. Try at least two different deep network architectures. Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab.\n",
    "\n",
    "### 10 points] Compare the performance of your best wide and deep network to a standard multi-layer perceptron (MLP) using the receiver operating characteristic and area under the curve.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exceptional Work (10 points total)\n",
    "   \n",
    "### One idea: Investigate which cross-product features are most important and hypothesize why.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
