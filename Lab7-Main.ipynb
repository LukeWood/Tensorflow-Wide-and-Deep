{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Car Evaluation ðŸš— 2.5 (McQueen Edition)\n",
    "   \n",
    "## Lab Seven: Wide and Deep Network Architectures\n",
    "   \n",
    "### Justin Ledford, Luke Wood, Traian Pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import plotly\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dataset Selection\n",
    "\n",
    "Select a dataset identically to lab one. That is, the dataset must be table data. In terms of generalization performance, it is helpful to have a large dataset for building a wide and deep network. It is also helpful to have many different categorical features to create the embeddings and cross-product embeddings. It is fine to perform binary classification or multi-class classification.\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/\n",
    "\n",
    "___ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preparation (40 points total)\n",
    "   \n",
    "### [10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). \n",
    "   \n",
    "### [10 points] Identify groups of features in your data that should be combined into cross-product features.\n",
    "   \n",
    "### [10 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "   \n",
    "### [10 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "\n",
    "# Get column names\n",
    "r = requests.get('https://raw.githubusercontent.com/LukeWoodSMU/WillBeRenamed/master/col_names.txt')\n",
    "\n",
    "if r.status_code == 200:\n",
    "    columns = r.text.split('\\n')[:-1]\n",
    "else:\n",
    "    print('Error loading column names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'class of worker', 'industry code', 'occupation code', 'education', 'wage per hour', 'enrolled in edu inst last wk', 'marital status', 'major industry code', 'major occupation code', 'race', 'hispanic origin', 'sex', 'member of a labor union', 'reason for unemployment', 'full or part time employment stat', 'capital gains', 'capital losses', 'dividends from stocks', 'tax filer status', 'region of previous residence', 'state of previous residence', 'detailed household and family stat', 'detailed household summary in household', 'migration code-change in msa', 'migration code-change in reg', 'migration code-move within reg', 'live in this house 1 year ago', 'migration prev res in sunbelt', 'num persons worked for employer', 'family members under 18', 'country of birth father', 'country of birth mother', 'country of birth self', 'citizenship', 'own business or self employed', \"fill inc questionnaire for veteran's admin\", 'veterans benefits', 'weeks worked in year', 'year', 'income']\n"
     ]
    }
   ],
   "source": [
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>class of worker</th>\n",
       "      <th>industry code</th>\n",
       "      <th>occupation code</th>\n",
       "      <th>education</th>\n",
       "      <th>wage per hour</th>\n",
       "      <th>enrolled in edu inst last wk</th>\n",
       "      <th>marital status</th>\n",
       "      <th>major industry code</th>\n",
       "      <th>major occupation code</th>\n",
       "      <th>...</th>\n",
       "      <th>country of birth father</th>\n",
       "      <th>country of birth mother</th>\n",
       "      <th>country of birth self</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>own business or self employed</th>\n",
       "      <th>fill inc questionnaire for veteran's admin</th>\n",
       "      <th>veterans benefits</th>\n",
       "      <th>weeks worked in year</th>\n",
       "      <th>year</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Self-employed-not incorporated</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Precision production craft &amp; repair</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10th grade</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Foreign born- Not a citizen of U S</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                  class of worker  industry code  occupation code  \\\n",
       "0   73                  Not in universe              0                0   \n",
       "1   58   Self-employed-not incorporated              4               34   \n",
       "2   18                  Not in universe              0                0   \n",
       "3    9                  Not in universe              0                0   \n",
       "4   10                  Not in universe              0                0   \n",
       "\n",
       "                     education  wage per hour enrolled in edu inst last wk  \\\n",
       "0         High school graduate              0              Not in universe   \n",
       "1   Some college but no degree              0              Not in universe   \n",
       "2                   10th grade              0                  High school   \n",
       "3                     Children              0              Not in universe   \n",
       "4                     Children              0              Not in universe   \n",
       "\n",
       "   marital status           major industry code  \\\n",
       "0         Widowed   Not in universe or children   \n",
       "1        Divorced                  Construction   \n",
       "2   Never married   Not in universe or children   \n",
       "3   Never married   Not in universe or children   \n",
       "4   Never married   Not in universe or children   \n",
       "\n",
       "                  major occupation code    ...     country of birth father  \\\n",
       "0                       Not in universe    ...               United-States   \n",
       "1   Precision production craft & repair    ...               United-States   \n",
       "2                       Not in universe    ...                     Vietnam   \n",
       "3                       Not in universe    ...               United-States   \n",
       "4                       Not in universe    ...               United-States   \n",
       "\n",
       "  country of birth mother country of birth self  \\\n",
       "0           United-States         United-States   \n",
       "1           United-States         United-States   \n",
       "2                 Vietnam               Vietnam   \n",
       "3           United-States         United-States   \n",
       "4           United-States         United-States   \n",
       "\n",
       "                            citizenship own business or self employed  \\\n",
       "0     Native- Born in the United States                             0   \n",
       "1     Native- Born in the United States                             0   \n",
       "2   Foreign born- Not a citizen of U S                              0   \n",
       "3     Native- Born in the United States                             0   \n",
       "4     Native- Born in the United States                             0   \n",
       "\n",
       "  fill inc questionnaire for veteran's admin  veterans benefits  \\\n",
       "0                            Not in universe                  2   \n",
       "1                            Not in universe                  2   \n",
       "2                            Not in universe                  2   \n",
       "3                            Not in universe                  0   \n",
       "4                            Not in universe                  0   \n",
       "\n",
       "   weeks worked in year  year     income  \n",
       "0                     0    95   - 50000.  \n",
       "1                    52    94   - 50000.  \n",
       "2                     0    95   - 50000.  \n",
       "3                     0    94   - 50000.  \n",
       "4                     0    94   - 50000.  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "        'https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.data.gz',\n",
    "        compression='gzip', header=None, index_col=False)\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "        'https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.test.gz',\n",
    "        compression='gzip', header=None, index_col=False)\n",
    "\n",
    "\n",
    "# Remove weight columns\n",
    "df_train.drop(24, 1, inplace=True)\n",
    "df_test.drop(24, 1, inplace=True)\n",
    "\n",
    "df_train.columns = columns\n",
    "df_test.columns = columns\n",
    "\n",
    "# Remove rows with missing data and reset index\n",
    "df_train.replace(to_replace=' ?',value=np.nan, inplace=True)\n",
    "df_train.dropna(inplace=True)\n",
    "df_train.reset_index()\n",
    "\n",
    "df_test.replace(to_replace=' ?',value=np.nan, inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "df_test.reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process data:\n",
    "\n",
    "# check income values consistent (only 2 values)\n",
    "\n",
    "# replace categorical with one hot encoding\n",
    "# scale continuous\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "labels = dict() \n",
    "\n",
    "r = requests.get('https://raw.githubusercontent.com/LukeWoodSMU/WillBeRenamed/master/categorical.txt')\n",
    "categorical_labels = r.text.split('\\n')[:-1]\n",
    "\n",
    "for col in categorical_labels:\n",
    "    # strip extra space in strings\n",
    "    if df_train[col].dtype == 'object':\n",
    "        df_train[col] = df_train[col].str.strip()\n",
    "    if df_test[col].dtype == 'object':\n",
    "        df_test[col] = df_test[col].str.strip()\n",
    "        \n",
    "    # convert to ints for one hot encoder to work\n",
    "    \n",
    "    # keep labels for reference \n",
    "    labels[col] = df_train[col].unique()\n",
    "    \n",
    "    df_train[col].replace(to_replace=df_train[col].unique(),\n",
    "                            value=np.arange(len(df_train[col].unique())),\n",
    "                            inplace=True)\n",
    "    df_test[col].replace(to_replace=df_test[col].unique(),\n",
    "                            value=np.arange(len(df_test[col].unique())),\n",
    "                            inplace=True)\n",
    "    \n",
    "r = requests.get('https://raw.githubusercontent.com/LukeWoodSMU/WillBeRenamed/master/continuous.txt')\n",
    "continuous_labels = r.text.split('\\n')[:-1]\n",
    "\n",
    "\n",
    "for col in continuous_labels:\n",
    "    df_train[col] = df_train[col].astype(np.float32)\n",
    "    df_test[col] = df_test[col].astype(np.float32)\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    df_train[col] = ss.fit_transform(df_train[col].values.reshape(-1, 1))\n",
    "    df_test[col] = ss.transform(df_test[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.learn.python import SKCompat\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "tf.logging.set_verbosity(tf.logging.WARN) # control the verbosity of tensor flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's start with the TF example (manipulated to work with new syntax)\n",
    "# https://www.tensorflow.org/tutorials/wide_and_deep\n",
    "def process_input(df, label_header, categ_headers, numeric_headers):\n",
    "    # input: what ever you need it to be\n",
    "    # output: (dict of feature columns as tensors), (labels as tensors)\n",
    "    \n",
    "    # ========Process Inputs=========\n",
    "    # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "    # the values of that column stored in a constant Tensor.\n",
    "    continuous_cols = {k: tf.expand_dims( # make it a column vector\n",
    "                            tf.cast( # cast to a float32\n",
    "                                tf.constant(df[k].values), \n",
    "                                tf.float32), \n",
    "                            1)\n",
    "                       for k in numeric_headers}\n",
    "    \n",
    "    # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "    # to the values of that column stored as constant Tensors (numeric)\n",
    "    # then use tensor flow to one hot encode them using the given number of classes \n",
    "    # name of encoder is **_int need to map only to **\n",
    "    categorical_cols = {k: tf.one_hot(indices=tf.constant(df[k].values),\n",
    "                                      depth=len(df[k].unique())) \n",
    "                        for k in categ_headers}\n",
    "    \n",
    "    # Merges the two dictionaries into one.\n",
    "    feature_cols = dict(continuous_cols)\n",
    "    feature_cols.update(categorical_cols)\n",
    "    \n",
    "    # Convert the label column into a constant Tensor.\n",
    "    label = None\n",
    "    if label_header is not None:\n",
    "        label = tf.constant(df[label_header].values)\n",
    "        \n",
    "    return feature_cols, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': <tf.Tensor 'ExpandDims_14:0' shape=(95130, 1) dtype=float32>,\n",
       "  'capital gains': <tf.Tensor 'ExpandDims_16:0' shape=(95130, 1) dtype=float32>,\n",
       "  'capital losses': <tf.Tensor 'ExpandDims_17:0' shape=(95130, 1) dtype=float32>,\n",
       "  'citizenship': <tf.Tensor 'one_hot_60:0' shape=(95130, 5) dtype=float32>,\n",
       "  'class of worker': <tf.Tensor 'one_hot_33:0' shape=(95130, 9) dtype=float32>,\n",
       "  'country of birth father': <tf.Tensor 'one_hot_57:0' shape=(95130, 40) dtype=float32>,\n",
       "  'country of birth mother': <tf.Tensor 'one_hot_58:0' shape=(95130, 40) dtype=float32>,\n",
       "  'country of birth self': <tf.Tensor 'one_hot_59:0' shape=(95130, 40) dtype=float32>,\n",
       "  'detailed household and family stat': <tf.Tensor 'one_hot_49:0' shape=(95130, 37) dtype=float32>,\n",
       "  'detailed household summary in household': <tf.Tensor 'one_hot_50:0' shape=(95130, 8) dtype=float32>,\n",
       "  'dividends from stocks': <tf.Tensor 'ExpandDims_18:0' shape=(95130, 1) dtype=float32>,\n",
       "  'education': <tf.Tensor 'one_hot_36:0' shape=(95130, 17) dtype=float32>,\n",
       "  'family members under 18': <tf.Tensor 'one_hot_56:0' shape=(95130, 5) dtype=float32>,\n",
       "  \"fill inc questionnaire for veteran's admin\": <tf.Tensor 'one_hot_62:0' shape=(95130, 3) dtype=float32>,\n",
       "  'full or part time employment stat': <tf.Tensor 'one_hot_45:0' shape=(95130, 1) dtype=float32>,\n",
       "  'hispanic origin': <tf.Tensor 'one_hot_41:0' shape=(95130, 10) dtype=float32>,\n",
       "  'industry code': <tf.Tensor 'one_hot_34:0' shape=(95130, 52) dtype=float32>,\n",
       "  'live in this house 1 year ago': <tf.Tensor 'one_hot_54:0' shape=(95130, 3) dtype=float32>,\n",
       "  'major industry code': <tf.Tensor 'one_hot_38:0' shape=(95130, 24) dtype=float32>,\n",
       "  'major occupation code': <tf.Tensor 'one_hot_39:0' shape=(95130, 15) dtype=float32>,\n",
       "  'marital status': <tf.Tensor 'one_hot_37:0' shape=(95130, 7) dtype=float32>,\n",
       "  'member of a labor union': <tf.Tensor 'one_hot_43:0' shape=(95130, 3) dtype=float32>,\n",
       "  'migration code-change in msa': <tf.Tensor 'one_hot_51:0' shape=(95130, 9) dtype=float32>,\n",
       "  'migration code-change in reg': <tf.Tensor 'one_hot_52:0' shape=(95130, 8) dtype=float32>,\n",
       "  'migration code-move within reg': <tf.Tensor 'one_hot_53:0' shape=(95130, 9) dtype=float32>,\n",
       "  'migration prev res in sunbelt': <tf.Tensor 'one_hot_55:0' shape=(95130, 3) dtype=float32>,\n",
       "  'num persons worked for employer': <tf.Tensor 'ExpandDims_19:0' shape=(95130, 1) dtype=float32>,\n",
       "  'occupation code': <tf.Tensor 'one_hot_35:0' shape=(95130, 47) dtype=float32>,\n",
       "  'own business or self employed': <tf.Tensor 'one_hot_61:0' shape=(95130, 3) dtype=float32>,\n",
       "  'race': <tf.Tensor 'one_hot_40:0' shape=(95130, 5) dtype=float32>,\n",
       "  'reason for unemployment': <tf.Tensor 'one_hot_44:0' shape=(95130, 6) dtype=float32>,\n",
       "  'region of previous residence': <tf.Tensor 'one_hot_47:0' shape=(95130, 6) dtype=float32>,\n",
       "  'sex': <tf.Tensor 'one_hot_42:0' shape=(95130, 2) dtype=float32>,\n",
       "  'state of previous residence': <tf.Tensor 'one_hot_48:0' shape=(95130, 50) dtype=float32>,\n",
       "  'tax filer status': <tf.Tensor 'one_hot_46:0' shape=(95130, 6) dtype=float32>,\n",
       "  'veterans benefits': <tf.Tensor 'one_hot_63:0' shape=(95130, 3) dtype=float32>,\n",
       "  'wage per hour': <tf.Tensor 'ExpandDims_15:0' shape=(95130, 1) dtype=float32>,\n",
       "  'weeks worked in year': <tf.Tensor 'ExpandDims_20:0' shape=(95130, 1) dtype=float32>,\n",
       "  'year': <tf.Tensor 'one_hot_64:0' shape=(95130, 1) dtype=float32>},\n",
       " <tf.Tensor 'Const_87:0' shape=(95130,) dtype=string>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_input(df_train,'income',categorical_labels, continuous_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Modeling (50 points total)\n",
    "   \n",
    "### [20 points] Create a combined wide and deep network to classify your data using tensorflow.\n",
    "   \n",
    "### [20 points] Investigate generalization performance by altering the number of layers. Try at least two different deep network architectures. Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab.\n",
    "\n",
    "### 10 points] Compare the performance of your best wide and deep network to a standard multi-layer perceptron (MLP) using the receiver operating characteristic and area under the curve.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exceptional Work (10 points total)\n",
    "   \n",
    "### One idea: Investigate which cross-product features are most important and hypothesize why.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
